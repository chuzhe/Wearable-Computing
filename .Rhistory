swirl()
library(swirl)
swirl
x<-c(1,2)
xc
x
find.package("devtools")
find.package("devtools")
install.packages("devtools")
find.package("devtools")
library(devtool)
library(devtools)
find_rtools()
install.package("KernSmooth")
install.packages("KernSmooth")
library(KernSmooth)
x<-c(1,2,3)
x
mydata<-rnorm(100)
sd(mydata)
sd(mydata,na.rm=false)
sd(mydata,na.rm=FALSE)
sd(na.rm=FALSE,mydata)
sd(na.rm=FALSE,X=mydata)
sd(na.rm=FALSE,x=mydata)
add2<- function(x,y){
x+y
}
x<-add2(3,5)
x
search()
search()
y<-10
y<-10
f <- function(x){
y<-2
y^2+g(x)
}
g<-function(x){
x*y
}
f(3)
x<-matrix(1:4,2,2)
x
sys.time
Sys.time
Sys.time()
cube <- function(x, n) {
x^3
}
cube(3)
x <- 1:10
if(x > 5) {
x <- 0
}
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z<-10
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
y
data<-read.csv("hw1_data")
data<-read.csv("hw1_data.csv")
head(data)
data<-read.csv("specdata\002.csv")
data<-read.csv("specdata/002.csv")
head(data)
directory<-"specdata"
fileid <-2
filename <- c(directory,fileid)
filename
fileid<-1:10
test <- as.character(fileid)
test <- list.files(path=directory, pattern = .csv)
test <- list.files(path=directory)
test
test <- list.files(path=directory, pattern = ".csv")
head(test)
c(directory,test[1])
paste( c(directory,test[1]),sep="/")
x<-paste( c(directory,test[1]),sep="/")
x
x<-paste( c(directory,test[1]),collapes="/")
x
test[1]
paste(1:12)
paste("A", 1:6, sep = "")
paste("Today is", date())
paste(directory,test[2])
paste(directory,"/",test[2])
paste(directory,"/",test[2],seq="")
paste(directory,"/",test[2],collapse="")
paste(directory,"/",test[2],sep="")
pollutantmean(id=1:3)
pollutantmean(id=1:3)
pollutantmean(id=1:3)
debugSource('~/pollutantmean.R')
pollutantmean(id=1:3)
head(data)
head(data)
data
head(data)
head(data["sulfate"])
length(data["sulfate"])
length(data[["sulfate"])
length(data[["sulfate"]])
class(data[["sulfate"])
class(data[["sulfate"]])
class(data["sulfate"])
head(data["sulfate"])
head(data[["sulfate"]])
a<-numberic()
a<-numeric()
a
x <- c(0:10, 50)
xm <- mean(x)
xm
x
debugSource('~/pollutantmean.R')
pollutant(id=1:3)
pollutantmean(id=1:3)
pollutantmean(id=1:3)
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean("specdata", "sulfate", 1:10)
source('~/pollutantmean.R')
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean("specdata", "nitrate", 70:72)
pollutantmean("specdata", "nitrate", 23)
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
submit()
submit()
submit()
submit()
submit()
source('~/pollutantmean.R')
?seq_along
id = 1:5
id
b = seq_along(id)
b\
b
id = 5:8
b = seq_along(id)
b
source('~/complete.R')
complete("specdata", 1)
source('~/complete.R')
complete("specdata", 1)
source('~/complete.R')
complete("specdata", 1)
complete("specdata", c(2, 4, 8, 10, 12))
complete("specdata", c(2, 4, 8, 10, 12))
debugSource('~/complete.R')
complete("specdata", c(2, 4, 8, 10, 12))
complete("specdata", c(2, 4, 8, 10, 12))
complete("specdata", 30:25)
complete("specdata", 3)
submit)
submit()
submit()
submit()
filenames <- list.files(path=directory,pattern=".csv")
class(filenames)
length(filenames)
a=seq_along(filenames)
source('~/pollutantmean.R')
source('~/complete.R')
?cor
source('~/corr.R')
directory
corr(directory,400)
debugSource('~/corr.R')
corr(directory,400)
corr(directory)
nobs
cor(data[["sulfate"]],data[["nitrate"]])
cor(data["sulfate"],data["nitrate"])
head(data)
data[complete.case(data)]
data[complete.cases(data)]
complete.cases(data)
data[1000]
data[1000,]
data[complete.cases(data),]
data[["sulfate"]]
cor(data[["sulfate"]],data[["nitrate"]],na.rm=TRUE)
a<-1:10
b<-10:1
b
cor(a,b)
cor(data["sulfate"],data["nitrate"],na.rm=TRUE)
head(data["nitrate"])
cor(data["sulfate"])
var(data["sulfate"])
var(data["sulfate"],na.rm=TRUE)
var(data[["sulfate"]],na.rm=TRUE)
data[complete.cases(data),"sulfate"]
sulfate <- data[complete.cases(data),"sulfate"]
nitrate <- data[complete.cases(data),"nitrate"]
correlation <- c(correlation,cor(sulfate,nitrate))
correlation
debugSource('~/corr.R')
corr()
corr(directory)
cr <- corr("specdata", 150)
head(cr)
cr <- corr("specdata", 150)
head(cr)
rm(list = ls())
cr <- corr("specdata", 150)
> head(cr)
source('~/corr.R')
cr <- corr("specdata", 150)
> head(cr)
cr <- corr("specdata", 150)
cr <- corr("specdata", 150)
> head(cr)
source('~/corr.R')
cr <- corr("specdata", 150)
> head(cr)
cr <- corr("specdata", 150)
nobs
class(nobs)
threshold
class(threshold)
nobs>threshold
cr <- corr("specdata", 150)
cr <- corr("specdata", 150)
head(cr)
summary(cr)
cr <- corr("specdata", 400)
summary(cr)
cr <- corr("specdata", 5000)
summary(cr)
cr <- corr("specdata")
summary(cr)
submit()
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
submit()
submit()
submit()
source('~/corr.R')
?fread
FileLoc <- "C:\Users\Gabriel\Desktop\exdata-data-household_power_consumption\household_power_consumption.txt"
my_data <- fread(FileLoc)
library(data.table)
FileLoc <- "C:\Users\Gabriel\Desktop\exdata-data-household_power_consumption\household_power_consumption.txt"
my_data <- fread(FileLoc)
library(data.table)
FileLoc <- "C:\\Users\\Gabriel\\Desktop\\exdata-data-household_power_consumption\\household_power_consumption.txt"
my_data <- fread(FileLoc)
my_data <- fread(FileLoc,na.strings="?")
View(my_data)
View(my_data)
my_data[1]
my_data[1,1]
my_data[1][1]
my_data[1,1]
my_data[1,3]
class(my_data)
my_data[1,Date]
tables
tables()
tables()
sapply(my_data,class)
my_data <- fread(FileLoc,na.strings="?")[Date=c("16/12/2006","16/12/2006")]
top(my_data)
head(my_data)
my_data <- fread(FileLoc,na.strings="?")[Date=c("01/01/2007","01/02/2007")]
head(my_data)
my_data <- fread(FileLoc,na.strings="?")[Date==c("01/01/2007","01/02/2007")]
head(my_data)
my_data <- fread(FileLoc,na.strings="?")
head(my_data)
setkey(my_data,Date)
tables()
my_data['21/12/2006']
setkey(my_data,Date,Time)
my_data[J('21/12/2006','11:23:00']
my_data[J('21/12/2006','11:23:00')]
my_data[6840]
my_data[6840,]
my_data[1,]
head(my_data)
tail(my_data)
source('E:/Dropbox/Data Science Coursera/Exploratory Data Analysis/Projects/ExData_Plotting1/plot1.R')
my_data[6840,]
library(data.table)
FileLoc <- "C:\\Users\\Gabriel\\Desktop\\exdata-data-household_power_consumption\\household_power_consumption.txt"
my_data <- fread(FileLoc,na.strings="?")
my_data[6840,]
my_data <- fread(FileLoc,na.strings='?')
my_data[6840,]
my_data <- fread(FileLoc)
my_data[6840,]
my_data[J('21/12/2006','11:23:00')]
setkey(my_data,Date,Time)
my_data[J('21/12/2006','11:23:00')]
library(data.table)
FileLoc <- "C:\\Users\\Gabriel\\Desktop\\exdata-data-household_power_consumption\\household_power_consumption.txt"
my_data <- fread(FileLoc,na.strings='?')
setkey(my_data,Date,Time)
my_data[6840,]
my_data[J('21/12/2006','11:23:00')]
head(my_data)
my_data[1,]
my_data[2,]
tail(my_data)
View(my_data)
?view
?View
setkey(raw_data,Date)
raw_data['01/02/2007']
source('E:/Dropbox/Data Science Coursera/Exploratory Data Analysis/Projects/ExData_Plotting1/plot1.R')
View(PlotData)
tables()
?ppois
?dnorm
dnorm(0)
pnorm(0)
?ppois
ppois(10,15)
debugSource('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Quizz 2/Question 1.R')
source('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Quizz 2/Question 1.R')
install.packages("httpuv")
source('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Quizz 2/Question 1.R')
content(req)
content(req)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
?oauth_app
source('~/.active-rstudio-document')
install.packages("jsonlite")
source('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Quizz 2/Question 1.R')
req
source('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Quizz 2/Question 1.R')
req
content(req)
json1 = content(req)
json1[1,1:4]
json2 = jsonlite::fromJSON(toJOSON(json1))
install.packages("jsonlite")
install.packages("jsonlite")
json2 = jsonlite::fromJSON(toJOSON(json1))
json2 = jsonlite::fromJSON(toJSON(json1))
names(json1)
jasonData <- fromJSON(req)
library(jsonlite)
library(jsonlite)
jasonData <- fromJSON(req)
json2 = fromJSON(toJOSON(json1))
json2 = fromJSON(toJSON(json1))
names(json2)
json2$name
json2[[5]]
json2[[5]]$createdat
json2[[5]]$created_at
json2[[5]][[43]]
json2[5]
library(httr)
url <-  "http://biostat.jhsph.edu/~jleek/contact.html"
htmlfile = GET(url)
content2 = content(htmlfile,as="text")
parsedHtml = htmlParse(content2, asText=TRUE)
content2
library(httr)
library(XML)
url <-  "http://biostat.jhsph.edu/~jleek/contact.html"
htmlfile = GET(url)
content2 = content(htmlfile,as="text")
parsedHtml = htmlParse(content2, asText=TRUE)
parsedHtml
?xpathSApply
?xmlValue
?xpathSApply
parsedHtml
xpathSApply(parsedHtml,nchar)
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con)
close(con)
htmlCode
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
?read.fwf
x <- read.fwf(
file=url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"),
skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
head(x)
head(x[,4])
sum(x[,4])
tail(x[,4])
source('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Quizz 2/Question 5.R')
sum(x[,4])
?which
?sort
?dbinom
lambda <- seq(0,0.2,length=1000)
head(lambda)
likelihood <- dpois(5,94*lambda)/dpois(5,5)
plot(lambda,likelihood,frame=false,type="l",xlab=expression(lambda))
plot(lambda,likelihood,frame=FALSE,type="l",xlab=expression(lambda))
plot(lambda,likelihood,frame=FALSE,type="l",xlab=expression(lambda),LWD=3)
plot(lambda,likelihood,frame=FALSE,type="l",xlab=expression(lambda),lwd=3)
plot(lambda,likelihood,frame=FALSE,type="l",xlab=expression(lambda),lwd=3)
expression(lambda)
## Exploring the beta density
library(manipulate)
pvals <- seq(0.01, 0.99, length = 1000)
manipulate(
plot(pvals, dbeta(pvals, alpha, beta), type = "l", lwd = 3, frame = FALSE),
alpha = slider(0.01, 10, initial = 1, step = .5),
beta = slider(0.01, 10, initial = 1, step = .5)
)
?numcolwise
library(plyr)
?numcolwise
source('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Project/Wearable-Computing/run_analysis.R')
source('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Project/Wearable-Computing/run_analysis.R')
source('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Project/Wearable-Computing/run_analysis.R')
head(tidy)
head(tidy2)
tidy1 < merge(tidy,activity_labels)
tidy1 <- merge(tidy,activity_labels)
?identical
identical(tidy1,tidy2)
head(tidy1)
rm(tidy1)
tidy2$activityName <- NULL
head(tidy2)
identical(tidy,tidy2)
nrow(tidy)
nrow(tidy2)
ncol(tidy)
ncol(tidy2)
a <- tidy - tidy2
head(a)
a <- abs(tidy - tidy2)
sum(a)
?runif
library(data.table)
complete_data_dt <- data.table(complete.data)
complete_data_dt <- data.table(complete_data)
identical(complete_data,complete_data_dt)
head(complete_data_dt)
class(complete_data_dt)
source('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Project/Wearable-Computing/run_analysis.R')
source('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Project/Wearable-Computing/run_analysis.R')
source('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Project/Wearable-Computing/run_analysis.R')
rm(list=ls())
debugSource('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Project/Wearable-Computing/run_analysis.R')
debugSource('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Project/Wearable-Computing/run_analysis.R')
debugSource('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Project/Wearable-Computing/run_analysis.R')
View(tidy_dt)
View(tidy_plyr)
tidy_dt <- complete_data_dt[,lapply(.SD, mean), by =  c("activityID","SubjectID", "activityName") ]
View(tidy_dt)
?list
tidy_dt_2 <- complete_data_dt[,lapply(.SD, mean), by =  list(activityID,SubjectID, activityName) ]
View(tidy_dt_2)
?order
tidy_dt <- complete_data_dt[,lapply(.SD, mean), by =  list(activityID,SubjectID, activityName) ]
tidy_dt <- tidy_dt[order(activityID, SubjectID)]
View(tidy_dt)
wirte.table
?write.table
getwd()
source('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Project/Wearable-Computing/run_analysis.R')
source('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Project/Wearable-Computing/run_analysis.R')
write.table(tidy_plyr,file="tidy_plyr.txt",row.names=FALSE)
write.table(tidy_dt,file="tidy_dt.txt",row.names=FALSE)
write.csv(tidy_plyr,file="tidy_plyr.txt",row.names=FALSE)
write.csv(tidy_plyr,file="tidy_plyr.txt",row.names=FALSE)
write.csv(tidy_plyr,file="tidy_plyr.csv",row.names=FALSE)
tidy_plyr_read <- read.table("tidy_plyr.txt")
tidy_plyr_read <- read.csv("tidy_plyr.csv")
identical(tidy_plyr,tidy_plyr_read)
tidy_plyr_read
## relevant website: http://stackoverflow.com/questions/10787640/ddply-summarize-for-repeating-same-statistical-function-across-large-number-of
head(tidy_plyr_read)
tidy_plyr_read <- read.table("tidy_plyr.txt")
?read.table
tidy_plyr_read <- read.table("tidy_plyr.txt",sep=",")
?wirte.table
?write.table
write.table(tidy_plyr,file="tidy_plyr.txt",row.names=FALSE)
tidy_plyr_read <- read.table("tidy_plyr.txt")
identical(tidy_plyr,tidy_plyr_read)
write.csv(tidy_dt,file="tidy_dt.csv",row.names=FALSE)
2. merge training and testing data
rm(list=ls())
source('E:/Dropbox/Data Science Coursera/Getting and Cleaning Data/Project/Wearable-Computing/run_analysis.R')
